from sklearn import metrics
import matplotlib.pyplot as plt
import re
import spacy
import string
import numpy as np

nlp = spacy.load("en_core_web_sm")
stop_words = nlp.Defaults.stop_words
punctuations = string.punctuation


def text_preprocessing(sentence,remove_nonalphanumeric=0,remove_stopword=0,remove_urls=0,lemmatization=0,len_word_remove_flag=0):
    '''
    Function to perform cleaning of English text
    Supports following text cleaning operations:
    - Convert to lowercase
    - Remove mentions
    - Remove urls
    - Remove nonalphanumeric tokens
    - Lemmatize words
    - Remove stopwords
    - Remove words below 3 characters
    
    Input: Text sentence
    Arguments: Flags to be set to true to perform required text cleaning
    Output: Cleaned text sentence
    '''
    
    #covert to lower
    sentence = sentence.lower()
    
    #remove mentions
    sentence = re.sub("@[A-Za-z0-9]+","",sentence)
    
    
    #regex to remove tokens with alphanumeric
    sentence = re.sub(r'\b\w*\d\w*\b', ' ', sentence)
    
    if remove_urls==1:
        sentence = re.sub(r"http\S+|www\S+", "", sentence)
        
    #Python regex to remove non-alphanumeric characters
    if remove_nonalphanumeric==1:
        sentence = re.sub("[^A-Za-z0-9]", ' ', sentence)
    
    #if lemmatization required, create a space text object
    if lemmatization==1:
        doc = nlp(sentence)
        
        #lemmatize the sentence
        mytokens = [word.lemma_.strip() for word in doc]
    
    else:
        mytokens = sentence.split(' ')
        
    #remove words with length less than equal to 2
    if len_word_remove_flag==1:
        mytokens = [word for word in mytokens if len(word)>=3]
    
    if remove_stopword==1:
        mytokens = [word for word in mytokens if word not in stop_words]
        
    cleaned_sentence = ' '.join(mytokens)
    
    #remove multiple white spaces
    cleaned_sentence = re.sub('\s+', ' ', cleaned_sentence)
    
    return cleaned_sentence


def auc_roc(actual_label,predicted_positive_propensity):
    '''
    Function to calculate the AUC metric to evaluate the performance of classification model
    Input: 
    actual_label - Actual label associated with the record
    predicted_positive_propensity - Propensity generated by the model to classify the record as positive
    
    Output:
    rou_auc - AUC score
    fpr - False positive rate at different thresholds
    tpr - True positive rate at different cut-off thresholds 
    thresholds - Propensity thresholds
    
    '''
    y_true = np.array(actual_label)
    y_scores = np.array(predicted_positive_propensity)

    # Compute the AUC curve
    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_scores)
    roc_auc = metrics.auc(fpr, tpr)
    
    return (roc_auc,fpr,tpr,thresholds)